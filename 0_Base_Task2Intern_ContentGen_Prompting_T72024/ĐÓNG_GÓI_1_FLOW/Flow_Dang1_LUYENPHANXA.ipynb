{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Hoàn tất riêng lẻ các phần. Các phần có input - output: phần text\n",
    "2. Hoàn tất riêng lẻ các phần. Các phần có input - output: text vào file Excel và Audio vào đúng thư mục . \n",
    "3. Ghép nối các luồng tuần tự trong .ipynb\n",
    "4. Ghép và loại bỏ các phần thừa. \n",
    "5. Các tối ưu riêng lẻ từng phần về sau.  \n",
    "\n",
    "\n",
    "- Ver 1: Đẩy nhanh sản phẩm chia nhau hoặc outsource \n",
    "    - 1.1 tách nhỏ bài toán Prompting \n",
    "    - 1.2 xử lý input output chuẩn định dạng automatic\n",
    "- Ver 2: Làm tất các phần, đóng gói 1 luồng. \n",
    "    - 2.1 tích hợp công nghệ bên kia sao cho chuẩn công nghệ bên mình. (thêm gen content, gen audio, gen task 3). \n",
    "    - 2.2 tối ưu phần cũ (đóng gói thành các hàm). \n",
    "    - 2.3 ghép nối thông input và output dạng cơ bản nhất của đầu ra (excel nhưng chưa cần đủ các cột của nhập liệu). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hoàn tất riêng lẻ các phần. Các phần có input - output: phần text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để không thêm ```JSON ở đầu output:\n",
    "```\n",
    "    # Output: Return a JSON object with the following structure:\n",
    "    Ensure that the output is a valid JSON object without any additional formatting or keywords (such as JSON).\n",
    "```\n",
    "- Tiêu chuẩn JSON: Định dạng JSON chính thức không bao gồm bất kỳ từ khóa hoặc tiền tố nào trước dữ liệu thực tế.\n",
    "- Parsing: Các thư viện xử lý JSON như json.loads() trong Python mong đợi dữ liệu JSON thuần túy, không có bất kỳ tiền tố nào.\n",
    "- Tính nhất quán: Giữ cho output nhất quán với định dạng JSON tiêu chuẩn giúp đảm bảo tính tương thích với các công cụ và thư viện khác nhau.\n",
    "- Độ rõ ràng: JSON tự nó đã là một định dạng được định nghĩa rõ ràng, không cần thêm bất kỳ nhãn hoặc định danh nào."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-4o\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-zxUCZnIlYGiviDsNYEh8T3BlbkFJlKwiHfS9NfjWeTEHB3MB\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cmd \n",
    "curl -L -X POST \"http://103.253.20.13:25010/api/text-to-speech\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"hello. Its me.Can you tell me?\\\",\\\"voice\\\": \\\"en-AU-WilliamNeural\\\",\\\"speed\\\": 1}\" --output \"1.mp3\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "curl -L -X POST \"http://103.253.20.13:25010/api/text-to-speech\" -H \"Content-Type: application/json\" -d \"{\\\"text\\\": \\\"Chapter 2: What is the purpose of life? Translator: Luan Nguyen. Please keep listening, everyone. Some of you have been to this retreat before, while others are new to it. When you listen to the lecture, try to keep your mouth closed naturally and pay attention to what's being said. In Buddhism, there are two important terms that describe the journey of a practitioner: wisdom and unwisdom. So, what do they mean? Wisdom is about truly understanding things as they are. It's also known as right view or enlightenment. On the other hand, unwisdom means having an incorrect understanding of things and phenomena. This is also called wrong view, false thinking, or delusion. When you observe or examine any phenomenon, there are two types of knowledge to consider: the wisdom taught by the Buddha and the unwisdom of ordinary people. The goal of Buddhist practice is to overcome unwisdom and cultivate wisdom instead. Why is this the case? Well, it's because the way we live is determined by what we know. Let me give you an example: imagine a two-year-old child who sees a red-hot coal burning in the fireplace. Even though the child may recognize the object as a coal, they don't fully understand the danger of touching it with their bare hands. So, if there's no one around to stop them, they might grab the coal and burn their hands badly. But for adults, who have a better understanding of the danger of a burning coal, they wouldn't touch it with their bare hands or feet. By living according to this knowledge, they can avoid suffering from burns or injuries. Our knowledge determines how we live. Children with limited knowledge might touch a burning coal and suffer, while adults with a deeper understanding of risks will avoid touching it with bare hands, preventing unnecessary pain. In the same way, if someone's understanding of daily life is based on delusion, confusion, or wrong views, it's like being a child who doesn't understand the danger of touching a burning coal. This leads to conflicts with reality, and their life becomes filled with sorrow and suffering. If a person has wisdom, right view, and insight, and understands the truth about things and phenomena, their life won't be in conflict with reality. They won't experience grief or sorrow. As I mentioned earlier regarding wisdom and unwisdom, anyone can feel the crunchy texture when chewing on a sesame cracker - whether they are an Arhat, a wise person, or an ordinary individual. However, there are two types of knowledge that arise from this experience. One is the knowledge of unwisdom, which assumes that the brittle texture of the sesame crackers is the actual material nature of it, and that crispiness is an inherent quality of the sesame crackers. This type of knowledge is considered unwisdom, delusion, and illusion in Buddhism. The second understanding is that brittleness is a sensation created in one's mind, rather than being a property of matter. It arises from the teeth coming into contact with the sesame crackers, and is impermanent, ownerless, and non-possessive. This knowledge is wisdom. Therefore, not only should one examine the brittleness of phenomena, but all phenomena should be examined through these two types of knowledge. Why should we strive for wisdom? To attain it, live by it, to end confusion, gain insight, live in harmony with reality, and free ourselves from suffering.\\\",\\\"voice\\\": \\\"en-AU-WilliamNeural\\\",\\\"speed\\\": 1}\" --output \"1.mp3\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hàm gen 4 paragraphs và audio => Duyệt qua từng hàng của input để gen và lưu vào 1 sheet excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to 1.mp3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def text_to_speech(text, voice, speed, output_path):\n",
    "    url = \"http://103.253.20.13:25010/api/text-to-speech\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"text\": text,\n",
    "        \"voice\": voice,\n",
    "        \"speed\": speed\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"File saved to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Example usage\n",
    "text_to_speech(\"hello. Its me.Can you tell me?\", \"en-AU-WilliamNeural\", 1, \"1.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def gen_content_Dang1Listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_content_Dang1Listening(given_words, topic):\n",
    "    \"\"\"\n",
    "    Input: givern_words (gồm 6-9 cụm từ), 1 topic\n",
    "    Output: 4 đoạn văn, 4 list gồm các cụm, \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Act as an English Teacher. Your students are A2 English learners (CEFR).\n",
    "\n",
    "    Task for you: Write a short story, which includes 4 sections, with the content of each section based on given words and the topic.\n",
    "\n",
    "    Requirement for the task: \n",
    "    - These four sections must relate to each other and create a complete story that is easy for A2 level. \n",
    "    - The total length of four sections must not exceed 100 words.\n",
    "    - Four sections must be equal.\n",
    "    - Each section must contain at least 2-3 given words.\n",
    "    - You must use easy-to-understand vocabularies, suitable for A2 level.\n",
    "    - \n",
    "    Return a JSON object with the following structure:\n",
    "    Ensure that the output is a valid JSON object without any additional formatting or keywords (such as JSON).\n",
    "    {{\n",
    "        \"paragraph1\": \"content of section1\",\n",
    "        \"list1\": [\"word1\", \"word2\", \"word3\"],\n",
    "        \"paragraph2\": \"content of section2\",\n",
    "        \"list2\": [\"word4\", \"word5\", \"word6\"],\n",
    "        \"paragraph3\": \"content of section3\",\n",
    "        \"list3\": [\"word7\", \"word8\", \"word9\"],\n",
    "        \"paragraph4\": \"content of section4\",\n",
    "        \"list4\": [\"word10\", \"word11\", \"word12\"]\n",
    "    }}\n",
    "\n",
    "    The following are given words for each section and the topic:\n",
    "    Given words: {\", \".join(given_words)}\n",
    "    Topic: {topic}\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    # return response\n",
    "\n",
    "\n",
    "    # Validate and format the JSON response\n",
    "    try:\n",
    "        # Parse the response to ensure it's valid JSON\n",
    "        json_response = json.loads(response)\n",
    "        \n",
    "        # Re-serialize to ensure proper JSON formatting\n",
    "        return json.dumps(json_response, ensure_ascii=False, indent=None)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: The generated response is not valid JSON. Error details: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### given_words example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************B3MB. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m given_words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbanana\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcherry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melderberry\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhoneydew\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m topic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA Fruit Adventure\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_content_Dang1Listening\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgiven_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[1;32mIn[6], line 38\u001b[0m, in \u001b[0;36mgen_content_Dang1Listening\u001b[1;34m(given_words, topic)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mInput: givern_words (gồm 6-9 cụm từ), 1 topic\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mOutput: 4 đoạn văn, 4 list gồm các cụm, \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mAct as an English Teacher. Your students are A2 English learners (CEFR).\u001b[39m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124mTopic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 38\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# return response\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Validate and format the JSON response\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Parse the response to ensure it's valid JSON\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mget_completion\u001b[1;34m(prompt, model, temperature)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      7\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\resources\\chat\\completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:1261\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1249\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1257\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1258\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1259\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1260\u001b[0m     )\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1049\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************B3MB. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Example usage\n",
    "given_words = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\", \"grape\", \"honeydew\"]\n",
    "topic = \"A Fruit Adventure\"\n",
    "\n",
    "result = gen_content_Dang1Listening(given_words, topic)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "json_response = json.loads(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def gen_content_AND_audio_Dang1Listening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_content_AND_audio_Dang1Listening(given_words, topic, audio_folder_output):\n",
    "    \"\"\"\n",
    "    Input: givern_words (gồm 6-9 cụm từ), 1 topic, audio_folder_output\n",
    "    Output: 4 đoạn văn, 4 list gồm các cụm, và 4 audio đánh số từ 1 đến 4 được lưu vào thư mục output_path\n",
    "    \"\"\"\n",
    "\n",
    "    # Tạo 1 thư mục tên \"audio_output\" nếu chưa tồn tại, nếu tồn tại rồi thì bỏ qua\n",
    "    \n",
    "    if not os.path.exists(audio_folder_output):\n",
    "        os.makedirs(audio_folder_output)\n",
    "        print(f\"Đã tạo thư mục '{audio_folder_output}'\")\n",
    "    else:\n",
    "        print(f\"Thư mục '{audio_folder_output}' đã tồn tại\")\n",
    "\n",
    "    # Gen audio dựa vào hàm text_to_speech ở bên trên\n",
    "    response = gen_content_Dang1Listening(given_words, topic)\n",
    "    paragraph_dict = json.loads(response)  # Convert the string to a dictionary\n",
    "\n",
    "    # paragraphs = [\n",
    "    #     paragraph_dict.get(\"paragraph1\"),\n",
    "    #     paragraph_dict.get(\"paragraph2\"),\n",
    "    #     paragraph_dict.get(\"paragraph3\"),\n",
    "    #     paragraph_dict.get(\"paragraph4\")\n",
    "    # ]\n",
    "    \n",
    "    paragraphs = [paragraph_dict.get(f\"paragraph{i}\") for i in range(1, 5)]\n",
    "    phrase_lists = [paragraph_dict.get(f\"list{i}\") for i in range(1, 5)]\n",
    "\n",
    "    for i, paragraph in enumerate(paragraphs, start=1):\n",
    "        if paragraph:\n",
    "            output_path = f\"{audio_folder_output}/{i}.mp3\"\n",
    "            text_to_speech(text=paragraph, voice=\"en-AU-WilliamNeural\", speed=1, output_path=output_path)\n",
    "\n",
    "    return paragraphs, phrase_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thư mục 'new_output' đã tồn tại\n",
      "File saved to new_output/1.mp3\n",
      "File saved to new_output/2.mp3\n",
      "File saved to new_output/3.mp3\n",
      "File saved to new_output/4.mp3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Tom and Anna went on a fruit adventure. They found an apple tree and picked some apples. They also saw a banana tree nearby.',\n",
       "  'Next, they walked to a cherry orchard. The cherries were red and sweet. They ate some and put more in their basket.',\n",
       "  'They continued their adventure and found a fig tree. The figs were ripe and delicious. They also saw some elderberries.',\n",
       "  'Finally, they reached a grapevine. The grapes were juicy. They also found a honeydew melon. It was a fun fruit adventure!'],\n",
       " [['apple', 'banana', 'cherry'],\n",
       "  ['date', 'elderberry', 'fig'],\n",
       "  ['grape', 'honeydew', 'apple'],\n",
       "  ['banana', 'cherry', 'date']])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gen_content&audio_Dang1Listening\n",
    "gen_content_AND_audio_Dang1Listening(given_words=given_words, topic=topic, audio_folder_output=\"new_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def input_2_gen_content_AND_audio_2_excel: Duyệt qua từng hàng từ file Input, run hàm gen_content_audio để return paragraph và phrases_lists, sau đó lưu từng output vào file output excel\n",
    "Không nên def gen_content_AND_audio_AND_excel_Dang1Listening (cho 1 topic, 6-0 cụm, sau đó output được lưu vào excel, nhưng nếu như thế thì khi duyệt qua các hàng của 1 file excel để lấy topic và cụm => lại thành 1 loạt excel rời rạc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: \n",
    "\n",
    "```\n",
    "| Chủ đề                         | Cụm                                                              |\n",
    "|--------------------------------|------------------------------------------------------------------|\n",
    "| Talk about you working day     | half past eight am, seven am, noon, checking emails, answering phone calls, scheduling meetings, drink coffee, chat with colleagues, take a walk |\n",
    "| Talk about you working day (2) | at five pm, at a quarter to six pm, when my tasks are completed, satisfied, accomplished, productive |\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thư mục './out_folder/row_1' đã tồn tại\n",
      "File saved to ./out_folder/row_1/1.mp3\n",
      "File saved to ./out_folder/row_1/2.mp3\n",
      "File saved to ./out_folder/row_1/3.mp3\n",
      "File saved to ./out_folder/row_1/4.mp3\n",
      "Thư mục './out_folder/row_2' đã tồn tại\n",
      "File saved to ./out_folder/row_2/1.mp3\n",
      "File saved to ./out_folder/row_2/2.mp3\n",
      "File saved to ./out_folder/row_2/3.mp3\n",
      "File saved to ./out_folder/row_2/4.mp3\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './out_folder/output_dang1_LISTENING.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m input_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Hanoi University of Science and Technology\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mITE10-DS&AI-HUST\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLearn&Task\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPRODUCT_THECOACH\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTask2_ContentGeneration\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mĐÓNG_GÓI_1_FLOW\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSản xuất nội dung 01.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./out_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 89\u001b[0m result_df, output_file_path \u001b[38;5;241m=\u001b[39m \u001b[43minput_2_gen_content_AND_audio_2_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[85], line 80\u001b[0m, in \u001b[0;36minput_2_gen_content_AND_audio_2_excel\u001b[1;34m(input_file_path, output_folder)\u001b[0m\n\u001b[0;32m     63\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     64\u001b[0m         result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     65\u001b[0m         result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_part_1\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab_part_4\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     77\u001b[0m     ]\n\u001b[0;32m     78\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mappend(new_row)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mworkbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_excel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails have been written to Excel file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_excel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result_df, output_excel_file\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openpyxl\\workbook\\workbook.py:386\u001b[0m, in \u001b[0;36mWorkbook.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworksheets:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_sheet()\n\u001b[1;32m--> 386\u001b[0m \u001b[43msave_workbook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openpyxl\\writer\\excel.py:291\u001b[0m, in \u001b[0;36msave_workbook\u001b[1;34m(workbook, filename)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_workbook\u001b[39m(workbook, filename):\n\u001b[0;32m    280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the given workbook on the filesystem under the name filename.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    :param workbook: the workbook to save\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     archive \u001b[38;5;241m=\u001b[39m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZIP_DEFLATED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowZip64\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     workbook\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mmodified \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(tz\u001b[38;5;241m=\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\u001b[38;5;241m.\u001b[39mreplace(tzinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    293\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ExcelWriter(workbook, archive)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\zipfile\\__init__.py:1331\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './out_folder/output_dang1_LISTENING.xlsx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "\n",
    "def input_2_gen_content_AND_audio_2_excel(input_file_path: str, output_folder: str) -> Tuple[List[str], List[str], str]:\n",
    "    \"\"\"\n",
    "    Process the input file, generate content and audio, and save the results to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): Path to the input Excel file.\n",
    "        output_folder (str): Path to the folder where audio files and Excel file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[str], str]: A tuple containing lists of paragraphs, audio paths, and the path to the output Excel file.\n",
    "    \n",
    "    Prompt: \n",
    "    - Đọc file input file \n",
    "\n",
    "            ```\n",
    "            | Chủ đề                         | Cụm                                                              |\n",
    "            |--------------------------------|------------------------------------------------------------------|\n",
    "            | Talk about you working day     | half past eight am, seven am, noon, checking emails, answering phone calls, scheduling meetings, drink coffee, chat with colleagues, take a walk |\n",
    "            | Talk about you working day (2) | at five pm, at a quarter to six pm, when my tasks are completed, satisfied, accomplished, productive |\n",
    "\n",
    "```\n",
    "    - Tìm đến sheet \"Input bài nghe\"\n",
    "    - Duyệt qua từng hàng, trong từng hàng lấy topic ở cột: \"Chủ đề\", lấy các cụm ở cột \"Cụm\"\n",
    "    Mục tiêu return ra được `given_words`, `topic`, \n",
    "        - Sau đó lắp vào hàm def gen_content_AND_audio_Dang1Listening(given_words, topic, audio_folder_output) \n",
    "        để nhận về paragraph list chứa 4 đoạn paragraph1, 2, 3, 4 , và phrase_list chứa các cụm đã dùng để tạo 4 đoạn đó, \n",
    "\n",
    "        paragraphs = [paragraph_dict.get(f\"paragraph{i}\", \"\") for i in range(1, 5)]\n",
    "        phrase_lists = [paragraph_dict.get(f\"list{i}\", \"\") for i in range(1, 5)]\n",
    "        - Lưu audio vào thư mục row_id (với row_id là số hàng từ input_file)\n",
    "        - Lưu 1 file excel : \n",
    "            1. Bạn tạo 1 file excel nếu file chưa tạo, hoặc viết đè lên 1 file đã tạo. đặt tên \"output_dang1_LISTENING\"\n",
    "            2. Tạo 1 sheet tên là \"mix_listen_content\"\n",
    "            3. Sheet gồm các cột thông tin như trong ảnh\n",
    "            'id', 'content_part_1', 'content_part_2', 'content_part_3', 'content_part_4',\n",
    "               'audio_part_1', 'audio_part_2', 'audio_part_3', 'audio_part_4',\n",
    "               'vocab_part_1', 'vocab_part_2', 'vocab_part_3', 'vocab_part_4'\n",
    "    - Ở mỗi row_id tôi sẽ gen 4 audio, 4 audio này được lưu vào thư mục tên \"row_id\", \n",
    "    thư mục output_folder sẽ chứa các folder row_id này và file excel nhé\n",
    "\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_excel_file = f\"{output_folder}/output_dang1_LISTENING.xlsx\".replace(os.sep, '/')\n",
    "    df = pd.read_excel(input_file_path, sheet_name=\"Input bài nghe\")\n",
    "\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        row_id = index + 1\n",
    "        topic = row[\"Chủ đề\"]\n",
    "        given_words = row[\"Cụm\"].split(\", \")\n",
    "\n",
    "        row_folder = f\"{output_folder}/row_{row_id}\".replace(os.sep, '/')\n",
    "        os.makedirs(row_folder, exist_ok=True)\n",
    "\n",
    "        paragraphs, phrase_lists = gen_content_AND_audio_Dang1Listening(given_words, topic, row_folder)\n",
    "        audio_paths = [f\"{row_folder}/{i}.mp3\".replace(os.sep, '/') for i in range(1, 5)]\n",
    "\n",
    "        results.append({\n",
    "            'id': row_id,\n",
    "            'content_part_1': paragraphs[0],\n",
    "            'content_part_2': paragraphs[1],\n",
    "            'content_part_3': paragraphs[2],\n",
    "            'content_part_4': paragraphs[3],\n",
    "            'audio_part_1': audio_paths[0],\n",
    "            'audio_part_2': audio_paths[1],\n",
    "            'audio_part_3': audio_paths[2],\n",
    "            'audio_part_4': audio_paths[3],\n",
    "            'vocab_part_1': ', '.join(phrase_lists[0]),\n",
    "            'vocab_part_2': ', '.join(phrase_lists[1]),\n",
    "            'vocab_part_3': ', '.join(phrase_lists[2]),\n",
    "            'vocab_part_4': ', '.join(phrase_lists[3])\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = \"mix_listen_content\"\n",
    "    sheet.append([\n",
    "        'id', 'content_part_1', 'content_part_2', 'content_part_3', 'content_part_4',\n",
    "        'audio_part_1', 'audio_part_2', 'audio_part_3', 'audio_part_4',\n",
    "        'vocab_part_1', 'vocab_part_2', 'vocab_part_3', 'vocab_part_4'\n",
    "    ])\n",
    "\n",
    "    for _, result in result_df.iterrows():\n",
    "        new_row = [\n",
    "            result['id'],\n",
    "            result['content_part_1'],\n",
    "            result['content_part_2'],\n",
    "            result['content_part_3'],\n",
    "            result['content_part_4'],\n",
    "            result['audio_part_1'],\n",
    "            result['audio_part_2'],\n",
    "            result['audio_part_3'],\n",
    "            result['audio_part_4'],\n",
    "            result['vocab_part_1'],\n",
    "            result['vocab_part_2'],\n",
    "            result['vocab_part_3'],\n",
    "            result['vocab_part_4']\n",
    "        ]\n",
    "        sheet.append(new_row)\n",
    "\n",
    "    workbook.save(output_excel_file)\n",
    "    print(f\"Details have been written to Excel file '{output_excel_file}'\")\n",
    "\n",
    "    return result_df, output_excel_file\n",
    "\n",
    "# Example usage\n",
    "input_file_path = r\"D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\input_TOPIC_and_PHRASES.xlsx\"\n",
    "output_folder = \"./out_folder\"\n",
    "\n",
    "result_df, output_file_path = input_2_gen_content_AND_audio_2_excel(input_file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def ex1_DIEN_VAO_CHO_TRONG_Dang1Listening => Sau đó: duyệt qua từng hàng để lưu từng output lưu vào file excel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def ex1_DIEN_VAO_CHO_TRONG_Dang1Listening(input_text, terms_list):\n",
    "    \"\"\"\n",
    "    Return: 1 câu đục ở 2 chỗ là từ đơn (thuộc các cụm đã cho ở đoạn 1). Đáp án gồm 2 đáp án đơn đúng và 4-5 đáp án đơn sai.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    # Designation(S) - Role(R) - Contextualization (C):\n",
    "    You are a content creation expert in creating exercises for language learning.\n",
    "\n",
    "    Your task: Create a fill-in-the-blank exercise based on:\n",
    "    - the given input text: \"{input_text}\"\n",
    "    - and terms from the given list: {terms_list}.\n",
    "\n",
    "    -------------------\n",
    "    # Instructions (I):\n",
    "    1. Get 'selected_term' and get 'question': \n",
    "    !!! IMPORTANT NOTE: We treat compound nouns and compound adjectives with hyphens as SINGLE WORD. (some SINGLE WORD examples: a, an, the, Nam, 15-minute, work, now, ...)\n",
    "    Select 2 single words (MUST BE SINGLE WORDS) from 2 terms of the terms in the `terms_list`\n",
    "    and replace them (MUST BE 2 SINGLE WORDS) with \"__\" to create a question.\n",
    "\n",
    "    2. Create 'answers_list' answer: Create 7 answer choices: including the 2 replaced words and 5 wrong words (wrong words should seem plausible but incorrect).\n",
    "    MANDATORY: ALL 7 answer choices MUST BE SINGLE WORDS. \n",
    "\n",
    "    3. Return a JSON object with the keys: input_text, selected_term, question, words.\n",
    "\n",
    "    -------------------\n",
    "    # Output: Return a JSON object with the following structure:\n",
    "    Ensure that the output is a valid JSON object without any additional formatting or keywords.\n",
    "\n",
    "    {{\n",
    "        \"input_text\": \"The original input text `input_text`\",\n",
    "        \"selected_term\": [\"selected term 1\", \"selected term 2\"],\n",
    "        \"question\": \"The input text with the two SINGLE WORDS replaced by __\",\n",
    "        \"answers_list\": [\"replaced_single_word_1\", \"replaced_single_word_2\", \"wrong_single_word_1\", \"wrong_single_word_2\", \"wrong_single_word_3\", \"wrong_single_word_4\", \"wrong_single_word_5\"]\n",
    "    }}\n",
    "\n",
    "\n",
    "    # Example of expected output format:\n",
    "\n",
    "    {{\n",
    "        \"input_text\": \"Anna works in an office. She handles the paperwork and does repetitive tasks every day. Even though the salary is low, she tries to learn to enjoy her job.\",\n",
    "        \"selected_term\": [\"the paperwork\", \"to enjoy her job\"],\n",
    "        \"question\": \"Anna works in an office. She handles the __ and does repetitive tasks every day. Even though salary is low, she tries to learn to __ her job.\",\n",
    "        \"answers_list\": [\"paperwork\", \"enjoy\", \"tasks\", \"office\", \"work\", \"learn\", \"handle\"]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt, temperature=0)\n",
    "    # return response\n",
    "\n",
    "    # Để an toàn thì response nên trả ra theo cách này để loads luôn \n",
    "    # Validate JSON response\n",
    "    try:\n",
    "        return response\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: The generated response is not valid JSON. Please check the output.\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"input_text\": \"Anna and Ben went to the market. They bought an apple and a banana.\",\n",
      "    \"selected_term\": [\"apple\", \"banana\"],\n",
      "    \"question\": \"Anna and Ben went to the market. They bought an __ and a __.\",\n",
      "    \"answers_list\": [\"apple\", \"banana\", \"cherry\", \"market\", \"went\", \"bought\", \"they\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = gen_content_Dang1Listening(given_words, topic)\n",
    "\n",
    "# Convert the string to a dictionary\n",
    "paragraph_dict = json.loads(response)\n",
    "\n",
    "# Extract \"paragraph1\" and \"list1\" from response\n",
    "paragraph1 = paragraph_dict.get(\"paragraph1\")\n",
    "list1 = paragraph_dict.get(\"list1\")\n",
    "response1 = ex1_DIEN_VAO_CHO_TRONG_Dang1Listening(paragraph1, list1)\n",
    "print(response1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "paragraph1: Emma wakes up at seven am. She gets ready and makes a cup of coffee. She drinks coffee and eats toast for breakfast.\n",
      "list1: ['seven am', 'drink coffee']\n",
      "\n",
      "\n",
      "{\n",
      "    \"input_text\": \"Emma wakes up at seven am. She gets ready and makes a cup of coffee. She drinks coffee and eats toast for breakfast.\",\n",
      "    \"selected_term\": [\"seven am\", \"drink coffee\"],\n",
      "    \"question\": \"Emma wakes up at __ am. She gets ready and makes a cup of coffee. She __ coffee and eats toast for breakfast.\",\n",
      "    \"answers_list\": [\"seven\", \"drink\", \"ready\", \"makes\", \"cup\", \"eats\", \"toast\"]\n",
      "} <class 'str'>\n",
      "<class 'str'>\n",
      "paragraph1: John starts his work day at nine am. He checks his emails and plans his tasks. By noon, he feels productive and happy.\n",
      "list1: ['productive']\n",
      "\n",
      "\n",
      "{\n",
      "    \"input_text\": \"John starts his work day at nine am. He checks his emails and plans his tasks. By noon, he feels productive and happy.\",\n",
      "    \"selected_term\": [\"emails\", \"productive\"],\n",
      "    \"question\": \"John starts his work day at nine am. He checks his __ and plans his tasks. By noon, he feels __ and happy.\",\n",
      "    \"answers_list\": [\"emails\", \"productive\", \"tasks\", \"work\", \"plans\", \"day\", \"happy\"]\n",
      "} <class 'str'>\n",
      "<class 'str'>\n",
      "paragraph1: Jane was studying and doing other things related to her major. She found it fun and interesting to learn new skills.\n",
      "list1: ['studying', 'doing other things', 'related to my major', 'fun and interesting']\n",
      "\n",
      "\n",
      "{\n",
      "    \"input_text\": \"Jane was studying and doing other things related to her major. She found it fun and interesting to learn new skills.\",\n",
      "    \"selected_term\": [\"studying\", \"fun\"],\n",
      "    \"question\": \"Jane was __ and doing other things related to her major. She found it __ and interesting to learn new skills.\",\n",
      "    \"answers_list\": [\"studying\", \"fun\", \"major\", \"skills\", \"things\", \"learn\", \"doing\"]\n",
      "} <class 'str'>\n",
      "<class 'str'>\n",
      "paragraph1: Max liked to plan everything ahead. He thought it was the best way to avoid stress. He did not like office drama, so he always tried to maintain focus when working.\n",
      "list1: ['plan everything ahead', 'office drama', 'maintain focus when working']\n",
      "\n",
      "\n",
      "{\n",
      "    \"input_text\": \"Max liked to plan everything ahead. He thought it was the best way to avoid stress. He did not like office drama, so he always tried to maintain focus when working.\",\n",
      "    \"selected_term\": [\"plan everything ahead\", \"office drama\"],\n",
      "    \"question\": \"Max liked to __ everything ahead. He thought it was the best way to avoid stress. He did not like __ drama, so he always tried to maintain focus when working.\",\n",
      "    \"answers_list\": [\"plan\", \"office\", \"work\", \"stress\", \"focus\", \"way\", \"tried\"]\n",
      "} <class 'str'>\n",
      "<class 'str'>\n",
      "paragraph1: In the late morning, Mr. Smith started to prepare for the meeting. He looked at the agenda review and noted the points for discussion.\n",
      "list1: ['late morning', 'agenda review']\n",
      "\n",
      "\n",
      "{\n",
      "    \"input_text\": \"In the late morning, Mr. Smith started to prepare for the meeting. He looked at the agenda review and noted the points for discussion.\",\n",
      "    \"selected_term\": [\"late morning\", \"agenda review\"],\n",
      "    \"question\": \"In the __ morning, Mr. Smith started to prepare for the meeting. He looked at the __ review and noted the points for discussion.\",\n",
      "    \"answers_list\": [\"late\", \"agenda\", \"early\", \"meeting\", \"points\", \"prepare\", \"noted\"]\n",
      "} <class 'str'>\n",
      "<class 'str'>\n",
      "paragraph1: John wanted to set a meeting with his clients. He knew quality results were important. He also needed to ensure timely completion of tasks.\n",
      "list1: ['quality results', 'timely completion']\n",
      "\n",
      "\n",
      "{\n",
      "    \"input_text\": \"John wanted to set a meeting with his clients. He knew quality results were important. He also needed to ensure timely completion of tasks.\",\n",
      "    \"selected_term\": [\"quality results\", \"timely completion\"],\n",
      "    \"question\": \"John wanted to set a meeting with his clients. He knew __ results were important. He also needed to ensure __ completion of tasks.\",\n",
      "    \"answers_list\": [\"quality\", \"timely\", \"important\", \"clients\", \"tasks\", \"meeting\", \"ensure\"]\n",
      "} <class 'str'>\n",
      "Data has been successfully written to ex1_Dang1Listening_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# def gồm các tham số file_path, sheet_name, column name\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\gen_content&audio_Dang1Listening.xlsx'\n",
    "\n",
    "# Load the Excel file\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Access the sheet \"Đã sửa content\"\n",
    "sheet_name = 'Input bài nghe'\n",
    "df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "# Extract the \"Exercise\" Answer column\n",
    "expected_answer_4_paragraph = df['4 đoạn']\n",
    "\n",
    "# Khởi tạo danh sách các từ điển để lưu các hàng dữ liệu\n",
    "data = []\n",
    "\n",
    "# Duyệt qua từng paragraph trong expected_answer_4paragraph\n",
    "for paragraph in expected_answer_4_paragraph: \n",
    "    # type paragraph: object\n",
    "    print(type(paragraph[1]))\n",
    "    # # Convert the string to a dictionary\n",
    "    paragraph_dict = json.loads(paragraph)\n",
    "\n",
    "    # Extract with key: \"paragraph1\" and \"list1\" \n",
    "    paragraph1 = paragraph_dict.get(\"paragraph1\")\n",
    "    list1 = paragraph_dict.get(\"list1\")\n",
    "\n",
    "    # Print the extracted values\n",
    "    print(\"paragraph1:\", paragraph1)\n",
    "    print(\"list1:\", list1)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    response = ex1_DIEN_VAO_CHO_TRONG_Dang1Listening(paragraph1, list1)\n",
    "    print(response, type(response1)) # str\n",
    "    # response = '{\"input_text\": \"Emma wakes up at seven am. She gets ready and makes a cup of coffee. She drinks coffee and eats toast for breakfast.\", \"selected_term\": [\"seven\", \"coffee\"], \"question\": \"Emma wakes up at __ am. She gets ready and makes a cup of coffee. She drinks __ and eats toast for breakfast.\", \"words\": [\"seven\", \"coffee\", \"toast\", \"ready\", \"cup\", \"drinks\", \"breakfast\"]}'\n",
    "    \n",
    "    response_dict = json.loads(response)\n",
    "\n",
    "    data.append({\n",
    "        \"question\": response_dict[\"question\"],\n",
    "        \"paragraph\": response_dict[\"input_text\"],\n",
    "        # \"words\": \", \".join(response1[\"words\"])  # Chuyển danh sách các từ thành chuỗi\n",
    "        \"answer\": \"\\n\".join(response_dict[\"answers_list\"])  # Chuyển danh sách các từ thành chuỗi với xuống dòng\n",
    "    })\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ghi DataFrame ra file Excel\n",
    "output_file_path = 'ex1_Dang1Listening_output.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def ex2_CHON_DAP_AN_PHU_HOP_Dang1Listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex2_CHON_DAP_AN_PHU_HOP_Dang1Listening(input_text, terms_list):\n",
    "    \"\"\"\n",
    "    Return: 1 câu hỏi từ đoạn 2, và đáp án đúng là 1 cụm trong các cụm từ đoạn 2 (3 cụm sai)\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    # Designation(S) - Role(R):\n",
    "    You are a content creation expert specializing in creating exercises for language learning.\n",
    "\n",
    "    # Contextualization (C):\n",
    "    Your task: Create a multiple-choice exercise with 4 options based on the given text: {input_text}\n",
    "    and a randomly selected term from the provided list: {terms_list}.\n",
    "    -----------------------\n",
    "    # Instructions (I):\n",
    "\n",
    "    ** Step 1: Select one term ('selected_term') from the given list: `terms_list`.\n",
    "    ** Step 2: Extract a sentence ('sentence') from the input text that contains the 'selected_term'.\n",
    "    ** Step 3: Create a 5W1H question ('question') based on the extracted sentence.\n",
    "    ** Step 4: Provide four answer options ('answers_list'):\n",
    "        - (a) The correct answer containing the 'selected_term'.\n",
    "        - (b, c, d) Plausible but incorrect answers.\n",
    "    ** Step 5: Return the output in JSON format.\n",
    "\n",
    "    ------------------\n",
    "    # Output: Return a JSON object with the following keys: selected_term, sentence, question, answers_list.\n",
    "    Ensure that the output is a valid JSON object without any additional formatting or keywords (such as JSON).\n",
    "\n",
    "    {{\n",
    "        \"selected_term\": \"example_term\",\n",
    "        \"sentence\": \"example_sentence\",\n",
    "        \"question\": \"example_question\",\n",
    "        \"answers_list\": [\n",
    "            \"correct_answer\",\n",
    "            \"incorrect_answer_1\",\n",
    "            \"incorrect_answer_2\",\n",
    "            \"incorrect_answer_3\"\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    --------------------\n",
    "    # Example:\n",
    "\n",
    "    {{\n",
    "        \"selected_term\": \"collaborative environment\",\n",
    "        \"sentence\": \"In their collaborative environment, creativity and innovation flourished.\",\n",
    "        \"question\": \"What kind of environment allowed creativity and innovation to flourish?\",\n",
    "        \"answers_list\": [\n",
    "            \"Collaborative environment\",\n",
    "            \"Competitive environment\",\n",
    "            \"Quiet environment\",\n",
    "            \"Stressful environment\"\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    # Self-Evaluation - Self-Reflection - Responsibility, Creative, Add Emotion - Evaluate():\n",
    "    1. Clear previous training data.\n",
    "    2. Assume the role of a learner given the input text.\n",
    "    3. Review the question and answer list carefully.\n",
    "    4. If the first answer in 'answers_list' is correct, proceed; if not, re-evaluate and start over.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = get_completion(prompt, temperature=0)\n",
    "    try:\n",
    "        return response\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: The generated response is not valid JSON. Please check the output.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"selected_term\": \"elderberry\",\n",
      "    \"sentence\": \"Next, they found a cherry tree.\",\n",
      "    \"question\": \"What did they find next?\",\n",
      "    \"answers_list\": [\n",
      "        \"A cherry tree\",\n",
      "        \"An elderberry bush\",\n",
      "        \"A fig tree\",\n",
      "        \"A date palm\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = gen_content_Dang1Listening(given_words, topic)\n",
    "\n",
    "# Convert the string to a dictionary\n",
    "paragraph_dict = json.loads(response)\n",
    "\n",
    "# Extract \"paragraph1\" and \"list1\" from response\n",
    "paragraph2 = paragraph_dict.get(\"paragraph2\")\n",
    "list2 = paragraph_dict.get(\"list2\")\n",
    "response2 = ex2_CHON_DAP_AN_PHU_HOP_Dang1Listening(paragraph2, list2)\n",
    "print(response2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragraph2: At half past eight am, Emma starts work from home. She begins by checking emails. She also schedules meetings for the day.\n",
      "list2: ['half past eight am', 'checking emails', 'scheduling meetings']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"checking emails\",\n",
      "    \"sentence\": \"She begins by checking emails.\",\n",
      "    \"question\": \"What does Emma start her workday with?\",\n",
      "    \"answers_list\": [\n",
      "        \"Checking emails\",\n",
      "        \"Making coffee\",\n",
      "        \"Reading reports\",\n",
      "        \"Scheduling meetings\"\n",
      "    ]\n",
      "} <class 'str'>\n",
      "paragraph2: At five pm, John finishes his main tasks. He feels satisfied with what he has done. He takes a short break with some tea.\n",
      "list2: ['at five pm', 'satisfied']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"satisfied\",\n",
      "    \"sentence\": \"He feels satisfied with what he has done.\",\n",
      "    \"question\": \"How does John feel about what he has done?\",\n",
      "    \"answers_list\": [\n",
      "        \"Satisfied\",\n",
      "        \"Disappointed\",\n",
      "        \"Confused\",\n",
      "        \"Indifferent\"\n",
      "    ]\n",
      "} <class 'str'>\n",
      "paragraph2: Jane liked that her job was flexible. She enjoyed working on different tasks.\n",
      "list2: ['flexible', 'working']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"flexible\",\n",
      "    \"sentence\": \"Jane liked that her job was flexible.\",\n",
      "    \"question\": \"What did Jane like about her job?\",\n",
      "    \"answers_list\": [\n",
      "        \"It was flexible.\",\n",
      "        \"It was high-paying.\",\n",
      "        \"It was close to her home.\",\n",
      "        \"It had a lot of benefits.\"\n",
      "    ]\n",
      "} <class 'str'>\n",
      "paragraph2: Max hated multitasking. He found that if he avoided it, he could get more done. Flexible working hours helped him stay happy and productive.\n",
      "list2: ['avoid multitasking', 'flexible working hours']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"flexible working hours\",\n",
      "    \"sentence\": \"Flexible working hours helped him stay happy and productive.\",\n",
      "    \"question\": \"What helped Max stay happy and productive?\",\n",
      "    \"answers_list\": [\n",
      "        \"Flexible working hours\",\n",
      "        \"Avoiding multitasking\",\n",
      "        \"Taking frequent breaks\",\n",
      "        \"Working from home\"\n",
      "    ]\n",
      "} <class 'str'>\n",
      "paragraph2: After lunch time, he gathered all the necessary documents. He checked the financial reports and made sure everything was accurate.\n",
      "list2: ['after lunch time', 'financial reports']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"financial reports\",\n",
      "    \"sentence\": \"He checked the financial reports and made sure everything was accurate.\",\n",
      "    \"question\": \"What did he check to ensure everything was accurate?\",\n",
      "    \"answers_list\": [\n",
      "        \"Financial reports\",\n",
      "        \"Meeting minutes\",\n",
      "        \"Inventory lists\",\n",
      "        \"Project plans\"\n",
      "    ]\n",
      "} <class 'str'>\n",
      "paragraph2: John checked his schedule. He had two hours free in the morning and one hour and a half free in the afternoon.\n",
      "list2: ['two hours', 'one hour and a half']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"two hours\",\n",
      "    \"sentence\": \"He had two hours free in the morning.\",\n",
      "    \"question\": \"How much free time did John have in the morning?\",\n",
      "    \"answers_list\": [\n",
      "        \"Two hours\",\n",
      "        \"One hour\",\n",
      "        \"Three hours\",\n",
      "        \"One hour and a half\"\n",
      "    ]\n",
      "} <class 'str'>\n",
      "Data has been successfully written to ex2_Dang1Listening_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# def gồm các tham số file_path, sheet_name, column name\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\gen_content&audio_Dang1Listening.xlsx'\n",
    "\n",
    "# Load the Excel file\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Access the sheet \"Đã sửa content\"\n",
    "sheet_name = 'Input bài nghe'\n",
    "df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "# Extract the \"Exercise\" Answer column\n",
    "expected_answer_4_paragraph = df['4 đoạn']\n",
    "\n",
    "# Khởi tạo danh sách các từ điển để lưu các hàng dữ liệu\n",
    "data = []\n",
    "\n",
    "# Duyệt qua từng paragraph trong expected_answer_4paragraph\n",
    "for paragraph in expected_answer_4_paragraph: \n",
    "\n",
    "    # # Convert the string to a dictionary\n",
    "    paragraph_dict = json.loads(paragraph)\n",
    "\n",
    "    # Extract with key: \"paragraph1\" and \"list1\" \n",
    "    paragraph2 = paragraph_dict.get(\"paragraph2\")\n",
    "    list2 = paragraph_dict.get(\"list2\")\n",
    "\n",
    "    # Print the extracted values\n",
    "    print(\"paragraph2:\", paragraph2)\n",
    "    print(\"list2:\", list2)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    response_str = ex2_CHON_DAP_AN_PHU_HOP_Dang1Listening(paragraph2, list2)\n",
    "    print(response_str, type(response_str)) # str\n",
    "\n",
    "    response_dict = json.loads(response_str)\n",
    "\n",
    "    data.append({\n",
    "        \"question\": response_dict[\"question\"],\n",
    "        # \"words\": \", \".join(response_dict[\"words\"])  # Chuyển danh sách các từ thành chuỗi\n",
    "        \"answer\": \"\\n\".join([answer.strip() for answer in response_dict[\"answers_list\"]]) # Chuyển danh sách các từ thành chuỗi với xuống dòng\n",
    "    })\n",
    "\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ghi DataFrame ra file Excel\n",
    "output_file_path = 'ex2_Dang1Listening_output.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def ex3_NOI_DE_TRA_LOI_Dang1Listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ex3_NOI_DE_TRA_LOI_Dang1Listening(input_text, terms_list): \n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - input_text: a string containing the text to base the exercise on.\n",
    "    - terms_list: a list of terms to choose from for creating the exercise. \n",
    "    <PARAMETERS ARE NOT NECESSARY, INCLUDED TO SYNCHRONIZE THE FUNCTIONS>\n",
    "\n",
    "    Output: JSON format: 1 câu hỏi cho cả đoạn 3 - NÓI ĐỂ TRẢ LỜI - trong nhập liệu có prompt để check phần trả lời\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the content of provided paragraph, create one question using 5W1H method. You must return one question only, and make sure the question is suitable for B1 English learners (CEFR).\n",
    "    The following is content of provided paragraph:\n",
    "    <paragraph>: {input_text}\n",
    "    Return: a valid JSON object without any additional formatting or keywords (such as JSON)\n",
    "    Example: \n",
    "    {{\n",
    "        \"question\": \"Where are you from?\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt, temperature=0)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": \"What had Tom never tried before?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = gen_content_Dang1Listening(given_words, topic)\n",
    "\n",
    "# Convert the string to a dictionary\n",
    "paragraph_dict = json.loads(response)\n",
    "\n",
    "# Extract \"paragraph\" and \"list\" from response\n",
    "paragraph3 = paragraph_dict.get(\"paragraph3\")\n",
    "list3 = paragraph_dict.get(\"list3\")\n",
    "response3 = ex3_NOI_DE_TRA_LOI_Dang1Listening(paragraph3, list3)\n",
    "print(response3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragraph3: Before noon, Emma is busy answering phone calls from clients. She chats with her colleagues during a short break.\n",
      "list3: ['noon', 'answering phone calls', 'chat with colleagues']\n",
      "\n",
      "\n",
      "{\n",
      "    \"question\": \"What does Emma do before noon?\"\n",
      "} <class 'str'>\n",
      "paragraph3: At a quarter to six pm, John reviews his schedule. He makes sure all important tasks are completed. He feels accomplished and content.\n",
      "list3: ['at a quarter to six pm', 'accomplished']\n",
      "\n",
      "\n",
      "{\n",
      "    \"question\": \"What does John do at a quarter to six pm?\"\n",
      "} <class 'str'>\n",
      "paragraph3: One day, Jane missed a deadline. She felt upset and knew she needed to fix it.\n",
      "list3: ['missed a deadline']\n",
      "\n",
      "\n",
      "{\n",
      "    \"question\": \"Why did Jane feel upset?\"\n",
      "} <class 'str'>\n",
      "paragraph3: One great thing about Max's job was the fewer meetings. That gave him time to work hard on his tasks and be confident in his work.\n",
      "list3: ['fewer meetings', 'work hard', 'to be confident']\n",
      "\n",
      "\n",
      "{\n",
      "    \"question\": \"Why did Max like his job?\"\n",
      "} <class 'str'>\n",
      "paragraph3: In the early afternoon, the team joined Mr. Smith for goal setting. They talked about the next steps and the project's progress.\n",
      "list3: ['early afternoon', 'goal setting', 'project updates']\n",
      "\n",
      "\n",
      "{\n",
      "    \"question\": \"What did the team discuss with Mr. Smith in the early afternoon?\"\n",
      "} <class 'str'>\n",
      "paragraph3: He decided to book the meeting room for forty-five minutes. John sent an email to confirm the meeting time.\n",
      "list3: ['meeting room', 'forty five minutes']\n",
      "\n",
      "\n",
      "{\n",
      "    \"question\": \"How long did he book the meeting room for?\"\n",
      "} <class 'str'>\n",
      "Data has been successfully written to ex3_Dang1Listening_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# def gồm các tham số file_path, sheet_name, column name\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\gen_content&audio_Dang1Listening.xlsx'\n",
    "# Load the Excel file\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Access the sheet \"Đã sửa content\"\n",
    "sheet_name = 'Input bài nghe'\n",
    "df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "# Extract the \"Exercise\" Answer column\n",
    "expected_answer_4_paragraph = df['4 đoạn']\n",
    "\n",
    "# Khởi tạo danh sách các từ điển để lưu các hàng dữ liệu\n",
    "data = []\n",
    "\n",
    "# Duyệt qua từng paragraph trong expected_answer_4paragraph\n",
    "for paragraph in expected_answer_4_paragraph: \n",
    "\n",
    "    # # Convert the string to a dictionary\n",
    "    paragraph_dict = json.loads(paragraph)\n",
    "\n",
    "    # Extract with key: \"paragraph1\" and \"list1\" \n",
    "    paragraph3 = paragraph_dict.get(\"paragraph3\")\n",
    "    list3 = paragraph_dict.get(\"list3\")\n",
    "\n",
    "    # Print the extracted values\n",
    "    print(\"paragraph3:\", paragraph3)\n",
    "    print(\"list3:\", list3)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    response_str = ex3_NOI_DE_TRA_LOI_Dang1Listening(paragraph3, list3)\n",
    "    print(response_str, type(response_str)) # str\n",
    "\n",
    "    response_dict = json.loads(response_str)\n",
    "\n",
    "    data.append({\n",
    "        \"question\": response_dict[\"question\"],\n",
    "        \"paragraph\": paragraph3\n",
    "        # \"answer\": \"\\n\".join([answer.strip() for answer in response_dict[\"answers_list\"]]) # Chuyển danh sách các từ thành chuỗi với xuống dòng\n",
    "    })\n",
    "\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ghi DataFrame ra file Excel\n",
    "output_file_path = 'ex3_Dang1Listening_output.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### def ex4_DIEN_PHAN_CON_THIEU_Dang1Listening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ex4_DIEN_PHAN_CON_THIEU_Dang1Listening(input_text, terms_list):\n",
    "    \"\"\"\n",
    "    Input: paragraph4, list 4 terms\n",
    "    Output: JSON format: Gồm đoạn 4 bị đục 1 chỗ là 1 cụm ở đoạn 4 và đáp án là DẠNG ĐÚNG của cụm bị đục. \n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "# Designation(S) - Role(R):\n",
    "You are a content creation expert in creating exercises for language learning.\n",
    "\n",
    "# Contextualization (C):\n",
    "Your task: Create a fill-type exercise based on the given {input_text} text\n",
    "and 1 random term from several terms in the given {terms_list} list.\n",
    "\n",
    "# Instructions (I):\n",
    "** Step 1: Choose 'selected_term': Choose 1 Choose only 1 term of the terms in the `terms_list`.  \n",
    "** Step 2: Find 'Dạng đúng của selected_term in `input_text`': exactly dạng chia động từ của `selected_term` in `input_text` \n",
    "(example: `selected_term` là: 'go to school' => Dạng đúng của selected_term in `input_text` chẳng hạn: 'going to school'.\n",
    " `selected_term` là: 'the marketing' => Dạng đúng của selected_term in `input_text`` chẳng hạn: 'marketing'. )\n",
    "** Step 3: Provide `question`: fill-type exercise bằng cách replace `selected_term` in `input_text` ban đầu with \"__\" to create a question. \n",
    "** Step 4: Provide `answer`: List contain 1 element the 'correct_form_of_selected_term' identified in Step 2.\n",
    "\n",
    "# Output: ONLY RETURN JSON format with key: selected_term, sentence, fill_in_the_blank_question, answers_list\n",
    "Ensure that the output is a valid JSON object without any additional formatting or keywords (such as JSON).\n",
    "{{  \n",
    "    \"selected_term\": \"selected_term\",\n",
    "    \"Dạng đúng của selected_term\": Dạng đúng của selected_term\n",
    "    \"sentence\": \"extracted sentence\",\n",
    "    \"question\": \"Your fill-type question here\", \n",
    "    \"answers_list\": [\"Dạng chia động từ đúng của `selected_term`\"]\n",
    "}}\n",
    "\n",
    "\n",
    "# Example:\n",
    "\n",
    "### Dạng đúng của cụm từ\n",
    "{{\n",
    "    \"selected_term\": \"go to the beach\",\n",
    "    \"sentence\": \"During the summer, they love going to the beach every weekend to relax and enjoy the sun.\",\n",
    "    \"question\": \"During the summer, they love __ every weekend to relax and enjoy the sun.\",\n",
    "    \"answers_list\": [\"going to the beach\"]\n",
    "}}\n",
    "\n",
    "### Dạng đúng của động từ \n",
    "{{\n",
    "    \"selected_term\": \"The marketing\",\n",
    "    \"sentence\": \"Each person in the team has a different role. Liam handles finance, Sara manages marketing, and Tom focuses on sales. They all work together to help the company succeed.\",\n",
    "    \"question\": \"Each person in the team has a different role. Liam handles finance, Sara manages __, and Tom focuses on sales. They all work together to help the company succeed.\",\n",
    "    \"answers_list\": [\"The marketing\"]\n",
    "}}\n",
    "\n",
    "\n",
    "\n",
    "# Self Evaluate - Self-Reflection - Responsibility, Creative, Add Emotion - Evaluate(): \n",
    "1. Xoá hết dữ liệu cũ đã được đào tạo. \n",
    "2. Bạn sẽ đóng vai là người học. Bạn được cho đoạn văn tại `input_text`. input_text: {input_text}\n",
    "3. Bạn được cho `fill_in_the_blank_question`.\n",
    "4. Bạn sẽ tự đọc kỹ đoạn văn, đọc kỹ câu hỏi, để tìm từ chính xác điền vào chỗ trống. \n",
    "5. Nếu câu trả lời TRÙNG VỚI `selected_term` => thì câu trả lời của bạn đúng rồi nhé. \n",
    "Nếu sai, bạn tự kiểm điểm lại mình, và BUỘC PHẢI QUAY LẠI ĐẦU TIÊN CỦA PROMPT ĐỂ KIỂM TRA LẠI . \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    response = get_completion(prompt, temperature=0)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"selected_term\": \"relax\",\n",
      "    \"Dạng đúng của selected_term\": \"relax\",\n",
      "    \"sentence\": \"Now, I can relax at home.\",\n",
      "    \"question\": \"Now, I can __ at home.\",\n",
      "    \"answers_list\": [\"relax\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "given_words = \"I feel satisfied and accomplished. It was a productive day at work.\"\n",
    "topic = \"satisfied, accomplished, productive\"\n",
    "\n",
    "response = gen_content_Dang1Listening(given_words, topic)\n",
    "\n",
    "# Convert the string to a dictionary\n",
    "paragraph_dict = json.loads(response)\n",
    "\n",
    "# Extract \"paragraph\" and \"list\" from response\n",
    "paragraph4 = paragraph_dict.get(\"paragraph4\")\n",
    "list4 = paragraph_dict.get(\"list4\")\n",
    "response4 = ex4_DIEN_PHAN_CON_THIEU_Dang1Listening(paragraph4, list4)\n",
    "print(response4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragraph: After lunch, Emma likes to take a walk in the park. It helps her relax and feel fresh for the rest of the day.\n",
      "list: ['take a walk']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"take a walk\",\n",
      "    \"Dạng đúng của selected_term\": \"taking a walk\",\n",
      "    \"sentence\": \"After lunch, Emma likes to take a walk in the park. It helps her relax and feel fresh for the rest of the day.\",\n",
      "    \"question\": \"After lunch, Emma likes __ in the park. It helps her relax and feel fresh for the rest of the day.\",\n",
      "    \"answers_list\": [\"taking a walk\"]\n",
      "} <class 'str'>\n",
      "paragraph: When his tasks are completed, John logs off his computer. He relaxes and thinks about his productive day at work.\n",
      "list: ['when my tasks are completed', 'productive']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"productive\",\n",
      "    \"Dạng đúng của selected_term\": \"productive\",\n",
      "    \"sentence\": \"When his tasks are completed, John logs off his computer. He relaxes and thinks about his productive day at work.\",\n",
      "    \"question\": \"When his tasks are completed, John logs off his computer. He relaxes and thinks about his __ day at work.\",\n",
      "    \"answers_list\": [\"productive\"]\n",
      "} <class 'str'>\n",
      "paragraph: Jane talked to her boss about being late for work. They made a plan so she wouldn't be late again.\n",
      "list: ['talked to my boss', 'been late for work']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"talked to my boss\",\n",
      "    \"Dạng đúng của selected_term\": \"talked to her boss\",\n",
      "    \"sentence\": \"Jane talked to her boss about being late for work. They made a plan so she wouldn't be late again.\",\n",
      "    \"question\": \"Jane __ about being late for work. They made a plan so she wouldn't be late again.\",\n",
      "    \"answers_list\": [\"talked to her boss\"]\n",
      "} <class 'str'>\n",
      "paragraph: Max liked to learn from his boss. His boss gave good advice and helped him improve. Max believed that with hard work, he could achieve much.\n",
      "list: ['learn from your boss', 'work hard']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"work hard\",\n",
      "    \"Dạng đúng của selected_term\": \"hard work\",\n",
      "    \"sentence\": \"Max liked to learn from his boss. His boss gave good advice and helped him improve. Max believed that with hard work, he could achieve much.\",\n",
      "    \"question\": \"Max liked to learn from his boss. His boss gave good advice and helped him improve. Max believed that with __, he could achieve much.\",\n",
      "    \"answers_list\": [\"hard work\"]\n",
      "} <class 'str'>\n",
      "paragraph: Finally, they focused on problem solving and discussed customer feedback. The meeting was successful, and the clients were happy.\n",
      "list: ['problem solving', 'customer feedback']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"problem solving\",\n",
      "    \"Dạng đúng của selected_term\": \"problem solving\",\n",
      "    \"sentence\": \"Finally, they focused on problem solving and discussed customer feedback. The meeting was successful, and the clients were happy.\",\n",
      "    \"question\": \"Finally, they focused on __ and discussed customer feedback. The meeting was successful, and the clients were happy.\",\n",
      "    \"answers_list\": [\"problem solving\"]\n",
      "} <class 'str'>\n",
      "paragraph: The clients replied quickly. They liked the open communication and the time set. The meeting would be in the conference room at the headquarter.\n",
      "list: ['open communication', 'conference room', 'headquarter']\n",
      "\n",
      "\n",
      "{\n",
      "    \"selected_term\": \"conference room\",\n",
      "    \"Dạng đúng của selected_term\": \"conference room\",\n",
      "    \"sentence\": \"The clients replied quickly. They liked the open communication and the time set. The meeting would be in the conference room at the headquarter.\",\n",
      "    \"question\": \"The clients replied quickly. They liked the open communication and the time set. The meeting would be in the __ at the headquarter.\",\n",
      "    \"answers_list\": [\"conference room\"]\n",
      "} <class 'str'>\n",
      "Data has been successfully written to ex4_Dang1Listening_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# def gồm các tham số file_path, sheet_name, column name\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\gen_content&audio_Dang1Listening.xlsx'\n",
    "\n",
    "# Load the Excel file\n",
    "excel_data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Access the sheet \"Đã sửa content\"\n",
    "sheet_name = 'Input bài nghe'\n",
    "df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "\n",
    "# Extract the \"Exercise\" Answer column\n",
    "expected_answer_4_paragraph = df['4 đoạn']\n",
    "\n",
    "# Khởi tạo danh sách các từ điển để lưu các hàng dữ liệu\n",
    "data = []\n",
    "\n",
    "# Duyệt qua từng paragraph trong expected_answer_4paragraph\n",
    "for paragraph in expected_answer_4_paragraph: \n",
    "\n",
    "    # # Convert the string to a dictionary\n",
    "    paragraph_dict = json.loads(paragraph)\n",
    "\n",
    "    # Extract with key: \"paragraph1\" and \"list1\" \n",
    "    paragraph4 = paragraph_dict.get(\"paragraph4\")\n",
    "    list4 = paragraph_dict.get(\"list4\")\n",
    "\n",
    "    # Print the extracted values\n",
    "    print(\"paragraph:\", paragraph4)\n",
    "    print(\"list:\", list4)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    response_str = ex4_DIEN_PHAN_CON_THIEU_Dang1Listening(paragraph4, list4)\n",
    "    print(response_str, type(response_str)) # str\n",
    "\n",
    "    response_dict = json.loads(response_str)\n",
    "\n",
    "    data.append({\n",
    "        \"question\": response_dict[\"question\"],\n",
    "        # \"words\": \", \".join(response_dict[\"words\"])  # Chuyển danh sách các từ thành chuỗi\n",
    "        \"answer\": \"\\n\".join([answer.strip() for answer in response_dict[\"answers_list\"]]) # Chuyển danh sách các từ thành chuỗi với xuống dòng\n",
    "    })\n",
    "\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ghi DataFrame ra file Excel\n",
    "output_file_path = 'ex4_Dang1Listening_output.xlsx'\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ALL:\n",
    "- H1: Output từng phần: gen bài xong =>  ex1, ex2, ex3, ex4\n",
    "    - Đối với hàm gen def input_2_gen_content_AND_audio_2_excel chỉ cần return: df0 để có thể gộp \n",
    "- H2: Output cuối: xong hết => return output: gen bài, ex1, 2, 3, 4. \n",
    "    -> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run all from file_after_gen_content (với việc nhận file sau gen 4 đoạn từ a Hoàng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet 'Ex1_listen_fill_choose' has been successfully written.\n",
      "Sheet 'Ex2_listen_choice' has been successfully written.\n",
      "Sheet 'Ex3_listen_speak' has been successfully written.\n",
      "Sheet 'Ex4_listen_fill_type' has been successfully written.\n",
      "Data has been successfully written to combined_Dang1Listening_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def process_excel(file_path, sheet_name, column_name, processing_func):\n",
    "    \"\"\"\n",
    "    Parameters: \n",
    "        - processing_func là 1 hàm: ... Khi gọi processing_func(paragraph_dict)\n",
    "    Input là file của a Hoàng,tìm đến cột Input bài nghe, để lấy paragraph1, 2, 3, 4 và list1, 2, 3, 4 để gen\n",
    "    Định dạng như này:\n",
    "        {\n",
    "        \"paragraph1\":\"John wakes up at seven am and gets ready for work. He starts work at half past eight am. The first thing he does is drink coffee.\",\n",
    "        \"list1\":[\"half past eight am\", \"seven am\", \"drink coffee\"],\n",
    "\n",
    "        \"paragraph2\":\"John begins his tasks by checking emails and answering phone calls. By noon, he is busy scheduling meetings.\",\n",
    "        \"list2\":[\"checking emails\", \"answering phone calls\", \"noon\", \"scheduling meetings\"],\n",
    "\n",
    "        \"paragraph3\":\"In the afternoon, John likes to take a walk and chat with colleagues when he feels tired. It helps him stay productive.\",\n",
    "        \"list3\":[\"take a walk\", \"chat with colleagues\", \"productive\"],\n",
    "\n",
    "        \"paragraph4\":\"At five pm, John finishes his work. When his tasks are completed, he feels satisfied and accomplished. He leaves the office at a quarter to six pm.\",\n",
    "        \"list4\":[\"at five pm\", \"when my tasks are completed\", \"satisfied\", \"accomplished\", \"at a quarter to six pm\"]\n",
    "        } \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Load the Excel file\n",
    "    excel_data = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Access the specified sheet\n",
    "    df = pd.read_excel(excel_data, sheet_name=sheet_name)\n",
    "    \n",
    "    # Extract the specified column\n",
    "    expected_answer_4_paragraph = df[column_name]\n",
    "    \n",
    "    # Khởi tạo danh sách các từ điển để lưu các hàng dữ liệu\n",
    "    data = []\n",
    "    \n",
    "    # Duyệt qua từng paragraph trong expected_answer_4_paragraph\n",
    "    for paragraph in expected_answer_4_paragraph:\n",
    "        # Convert the string to a dictionary\n",
    "        paragraph_dict = json.loads(paragraph)\n",
    "        \n",
    "        # Gọi hàm xử lý tùy chỉnh\n",
    "        response_str = processing_func(paragraph_dict)\n",
    "        response_dict = json.loads(response_str)\n",
    "    \n",
    "\n",
    "        # Determine which paragraph to use based on the processing function\n",
    "        if processing_func.__name__ == 'process_paragraph1':\n",
    "            paragraph_text = paragraph_dict.get(\"paragraph1\", \"\")\n",
    "        elif processing_func.__name__ == 'process_paragraph2':\n",
    "            paragraph_text = paragraph_dict.get(\"paragraph2\", \"\")\n",
    "        elif processing_func.__name__ == 'process_paragraph3':\n",
    "            paragraph_text = paragraph_dict.get(\"paragraph3\", \"\")\n",
    "        elif processing_func.__name__ == 'process_paragraph4':\n",
    "            paragraph_text = paragraph_dict.get(\"paragraph4\", \"\")\n",
    "        else:\n",
    "            paragraph_text = \"\"  # Default case if the function name doesn't match\n",
    "\n",
    "        data.append({\n",
    "            \"question\": response_dict[\"question\"],\n",
    "            \"paragraph\": paragraph_text,  # paragraph_dict.get(\"paragraph1, 2, 3, 4\"),     # paragraph1, 2, 3, 4 tương ứng các đoạn luôn\n",
    "            \"answer\": \"\\n\".join([answer.strip() for answer in response_dict.get(\"answers_list\", [])])\n",
    "        })\n",
    "    \n",
    "    # Tạo DataFrame từ dữ liệu\n",
    "    output_df = pd.DataFrame(data)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Define the file path and sheet name\n",
    "file_path = r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\gen_content&audio_Dang1Listening.xlsx'\n",
    "sheet_name = 'Input bài nghe'\n",
    "column_name = '4 đoạn'\n",
    "\n",
    "# Define the processing functions\n",
    "def process_paragraph1(paragraph_dict):\n",
    "    paragraph1 = paragraph_dict.get(\"paragraph1\")\n",
    "    list1 = paragraph_dict.get(\"list1\")\n",
    "    return ex1_DIEN_VAO_CHO_TRONG_Dang1Listening(paragraph1, list1)\n",
    "\n",
    "def process_paragraph2(paragraph_dict):\n",
    "    paragraph2 = paragraph_dict.get(\"paragraph2\")\n",
    "    list2 = paragraph_dict.get(\"list2\")\n",
    "    return ex2_CHON_DAP_AN_PHU_HOP_Dang1Listening(paragraph2, list2)\n",
    "\n",
    "def process_paragraph3(paragraph_dict):\n",
    "    paragraph3 = paragraph_dict.get(\"paragraph3\")\n",
    "    list3 = paragraph_dict.get(\"list3\")\n",
    "    return ex3_NOI_DE_TRA_LOI_Dang1Listening(paragraph3, list3)\n",
    "\n",
    "def process_paragraph4(paragraph_dict):\n",
    "    paragraph4 = paragraph_dict.get(\"paragraph4\")\n",
    "    list4 = paragraph_dict.get(\"list4\")\n",
    "    return ex4_DIEN_PHAN_CON_THIEU_Dang1Listening(paragraph4, list4)\n",
    "\n",
    "# Process each type of paragraph and store in DataFrames\n",
    "df1 = process_excel(file_path, sheet_name, column_name, process_paragraph1)\n",
    "df2 = process_excel(file_path, sheet_name, column_name, process_paragraph2)\n",
    "df3 = process_excel(file_path, sheet_name, column_name, process_paragraph3)\n",
    "df4 = process_excel(file_path, sheet_name, column_name, process_paragraph4)\n",
    "\n",
    "# Write all DataFrames to a single Excel file with different sheets\n",
    "output_file_path = 'combined_Dang1Listening_output.xlsx'\n",
    "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
    "    df1.to_excel(writer, sheet_name='Ex1_listen_fill_choose', index=False)\n",
    "    print(f\"Sheet 'Ex1_listen_fill_choose' has been successfully written.\")\n",
    "\n",
    "    df2.to_excel(writer, sheet_name='Ex2_listen_choice', index=False)\n",
    "    print(f\"Sheet 'Ex2_listen_choice' has been successfully written.\")\n",
    "    \n",
    "    df3.to_excel(writer, sheet_name='Ex3_listen_speak', index=False)\n",
    "    print(f\"Sheet 'Ex3_listen_speak' has been successfully written.\")\n",
    "\n",
    "    df4.to_excel(writer, sheet_name='Ex4_listen_fill_type', index=False)\n",
    "    print(f\"Sheet 'Ex4_listen_fill_type' has been successfully written.\")\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ver 1 - Run all from file_after_gen_content - CƯỜNG\n",
    "FROM file: \"input_TOPIC_and_PHRASES.xlsx\"  => "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thư mục './out_folder/row_1' đã tồn tại\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************B3MB. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m input_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Hanoi University of Science and Technology\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mITE10-DS&AI-HUST\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLearn&Task\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPRODUCT_THECOACH\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTask2_ContentGeneration\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mĐÓNG_GÓI_1_FLOW\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124minput_TOPIC_and_PHRASES.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./out_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 102\u001b[0m result_df, output_file_path \u001b[38;5;241m=\u001b[39m \u001b[43minput_2_gen_content_AND_audio_2_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m, in \u001b[0;36minput_2_gen_content_AND_audio_2_excel\u001b[1;34m(input_file_path, output_folder)\u001b[0m\n\u001b[0;32m     42\u001b[0m row_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/row_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(os\u001b[38;5;241m.\u001b[39msep, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(row_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m paragraphs, phrase_lists \u001b[38;5;241m=\u001b[39m \u001b[43mgen_content_AND_audio_Dang1Listening\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgiven_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m audio_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(os\u001b[38;5;241m.\u001b[39msep, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m)]\n\u001b[0;32m     48\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: row_id,\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent_part_1\u001b[39m\u001b[38;5;124m'\u001b[39m: paragraphs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab_part_4\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(phrase_lists[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     62\u001b[0m })\n",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m, in \u001b[0;36mgen_content_AND_audio_Dang1Listening\u001b[1;34m(given_words, topic, audio_folder_output)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThư mục \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_folder_output\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m đã tồn tại\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Gen audio dựa vào hàm text_to_speech ở bên trên\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgen_content_Dang1Listening\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgiven_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m paragraph_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)  \u001b[38;5;66;03m# Convert the string to a dictionary\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# paragraphs = [\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#     paragraph_dict.get(\"paragraph1\"),\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     paragraph_dict.get(\"paragraph2\"),\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#     paragraph_dict.get(\"paragraph3\"),\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#     paragraph_dict.get(\"paragraph4\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 38\u001b[0m, in \u001b[0;36mgen_content_Dang1Listening\u001b[1;34m(given_words, topic)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mInput: givern_words (gồm 6-9 cụm từ), 1 topic\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mOutput: 4 đoạn văn, 4 list gồm các cụm, \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mAct as an English Teacher. Your students are A2 English learners (CEFR).\u001b[39m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124mTopic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopic\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 38\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# return response\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Validate and format the JSON response\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Parse the response to ensure it's valid JSON\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mget_completion\u001b[1;34m(prompt, model, temperature)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      7\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_utils\\_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\resources\\chat\\completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:1261\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1249\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1257\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1258\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1259\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1260\u001b[0m     )\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\openai\\_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1049\u001b[0m )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************B3MB. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "\n",
    "def input_2_gen_content_AND_audio_2_excel(input_file_path: str, output_folder: str) -> Tuple[pd.DataFrame, str]:\n",
    "    \"\"\"\n",
    "    Input file: \n",
    "\n",
    "        - Đọc file input file \n",
    "\n",
    "            ```\n",
    "            | Chủ đề                         | Cụm                                                              |\n",
    "            |--------------------------------|------------------------------------------------------------------|\n",
    "            | Talk about you working day     | half past eight am, seven am, noon, checking emails, answering phone calls, scheduling meetings, drink coffee, chat with colleagues, take a walk |\n",
    "            | Talk about you working day (2) | at five pm, at a quarter to six pm, when my tasks are completed, satisfied, accomplished, productive |\n",
    "\n",
    "\n",
    "    Process the input file, generate content and audio, and save the results to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): Path to the input Excel file.\n",
    "        output_folder (str): Path to the folder where audio files and Excel file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, str]: A tuple containing the resulting DataFrame and the path to the output Excel file.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_excel_file = f\"{output_folder}/output_dang1_LISTENING.xlsx\".replace(os.sep, '/')\n",
    "    df = pd.read_excel(input_file_path, sheet_name=\"Input bài nghe\")\n",
    "\n",
    "    results = []\n",
    "    for index, row in df.iterrows():\n",
    "        row_id = index + 1\n",
    "        topic = row[\"Chủ đề\"]\n",
    "        given_words = row[\"Cụm\"].split(\", \")\n",
    "\n",
    "        row_folder = f\"{output_folder}/row_{row_id}\".replace(os.sep, '/')\n",
    "        os.makedirs(row_folder, exist_ok=True)\n",
    "\n",
    "        paragraphs, phrase_lists = gen_content_AND_audio_Dang1Listening(given_words, topic, row_folder)\n",
    "        audio_paths = [f\"{row_folder}/{i}.mp3\".replace(os.sep, '/') for i in range(1, 5)]\n",
    "\n",
    "        results.append({\n",
    "            'id': row_id,\n",
    "            'content_part_1': paragraphs[0],\n",
    "            'content_part_2': paragraphs[1],\n",
    "            'content_part_3': paragraphs[2],\n",
    "            'content_part_4': paragraphs[3],\n",
    "            'audio_part_1': audio_paths[0],\n",
    "            'audio_part_2': audio_paths[1],\n",
    "            'audio_part_3': audio_paths[2],\n",
    "            'audio_part_4': audio_paths[3],\n",
    "            'vocab_part_1': ', '.join(phrase_lists[0]),\n",
    "            'vocab_part_2': ', '.join(phrase_lists[1]),\n",
    "            'vocab_part_3': ', '.join(phrase_lists[2]),\n",
    "            'vocab_part_4': ', '.join(phrase_lists[3])\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    workbook = Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = \"mix_listen_content\"\n",
    "    sheet.append([\n",
    "        'id', 'content_part_1', 'content_part_2', 'content_part_3', 'content_part_4',\n",
    "        'audio_part_1', 'audio_part_2', 'audio_part_3', 'audio_part_4',\n",
    "        'vocab_part_1', 'vocab_part_2', 'vocab_part_3', 'vocab_part_4'\n",
    "    ])\n",
    "\n",
    "    for _, result in result_df.iterrows():\n",
    "        new_row = [\n",
    "            result['id'],\n",
    "            result['content_part_1'],\n",
    "            result['content_part_2'],\n",
    "            result['content_part_3'],\n",
    "            result['content_part_4'],\n",
    "            result['audio_part_1'],\n",
    "            result['audio_part_2'],\n",
    "            result['audio_part_3'],\n",
    "            result['audio_part_4'],\n",
    "            result['vocab_part_1'],\n",
    "            result['vocab_part_2'],\n",
    "            result['vocab_part_3'],\n",
    "            result['vocab_part_4']\n",
    "        ]\n",
    "        sheet.append(new_row)\n",
    "\n",
    "    workbook.save(output_excel_file)\n",
    "    print(f\"Details have been written to Excel file '{output_excel_file}'\")\n",
    "\n",
    "    return result_df, output_excel_file\n",
    "\n",
    "# Example usage\n",
    "input_file_path = r\"D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\input_TOPIC_and_PHRASES.xlsx\"\n",
    "output_folder = \"./out_folder\"\n",
    "\n",
    "result_df, output_file_path = input_2_gen_content_AND_audio_2_excel(input_file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response JSON for row 0: {\n",
      "    \"input_text\": \"Paragraph 1 about Talk about you working day\",\n",
      "    \"selected_term\": [\"half past eight am\", \"checking emails\"],\n",
      "    \"question\": \"Paragraph 1 about Talk about you __ day\",\n",
      "    \"answers_list\": [\"working\", \"emails\", \"half\", \"past\", \"eight\", \"am\", \"checking\"]\n",
      "}\n",
      "Response JSON for row 1: {\n",
      "    \"input_text\": \"Paragraph 1 about Talk about you working day (2)\",\n",
      "    \"selected_term\": [\"at five pm\", \"satisfied\"],\n",
      "    \"question\": \"Paragraph 1 about Talk about you working day (2) __ five pm __\",\n",
      "    \"answers_list\": [\"at\", \"satisfied\", \"about\", \"you\", \"day\", \"work\", \"tasks\"]\n",
      "}\n",
      "Response JSON for row 0: {\n",
      "    \"selected_term\": \"checking emails\",\n",
      "    \"sentence\": \"I usually start my day by checking emails to see if there are any urgent tasks that need my attention.\",\n",
      "    \"question\": \"What activity does the person usually start their day with?\",\n",
      "    \"answers_list\": [\n",
      "        \"Checking emails\",\n",
      "        \"Scheduling meetings\",\n",
      "        \"Answering phone calls\",\n",
      "        \"Drinking coffee\"\n",
      "    ]\n",
      "}\n",
      "Response JSON for row 1: {\n",
      "    \"selected_term\": \"satisfied\",\n",
      "    \"sentence\": \"I feel satisfied when my tasks are completed on time.\",\n",
      "    \"question\": \"How do I feel when my tasks are completed on time?\",\n",
      "    \"answers_list\": [\n",
      "        \"Satisfied\",\n",
      "        \"Stressed\",\n",
      "        \"Bored\",\n",
      "        \"Anxious\"\n",
      "    ]\n",
      "}\n",
      "Response JSON for row 0: {\n",
      "    \"question\": \"What do you do during your working day?\"\n",
      "}\n",
      "Response JSON for row 1: {\n",
      "    \"question\": \"What do you do during your working day?\"\n",
      "}\n",
      "Response JSON for row 0: {\n",
      "    \"selected_term\": \"checking emails\",\n",
      "    \"Dạng đúng của selected_term\": \"checking emails\",\n",
      "    \"sentence\": \"I usually start my day by checking emails to see if there are any urgent messages that need my attention.\",\n",
      "    \"question\": \"I usually start my day by __ to see if there are any urgent messages that need my attention.\",\n",
      "    \"answers_list\": [\"checking emails\"]\n",
      "}\n",
      "Response JSON for row 1: {\n",
      "    \"selected_term\": \"satisfied\",\n",
      "    \"Dạng đúng của selected_term\": \"satisfied\",\n",
      "    \"sentence\": \"I usually feel satisfied when my tasks are completed.\",\n",
      "    \"question\": \"I usually feel __ when my tasks are completed.\",\n",
      "    \"answers_list\": [\"satisfied\"]\n",
      "}\n",
      "Sheet 'Ex1_listen_fill_choose' has been successfully written.\n",
      "Sheet 'Ex1_listen_fill_choose' has been successfully written.\n",
      "Sheet 'Ex2_listen_choice' has been successfully written.\n",
      "Sheet 'Ex3_listen_speak' has been successfully written.\n",
      "Sheet 'Ex4_listen_fill_type' has been successfully written.\n",
      "Data has been successfully written to combined_Dang1Listening_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def process_excel(file_path, sheet_name, processing_func, content_col, vocab_col):\n",
    "    \"\"\"\n",
    "    - Input: là \n",
    "        | id | content_part_1                                                                 | content_part_2                                                                 | content_part_3                                                                 | content_part_4                                                | audio_part_1              | audio_part_2              | audio_part_3              | audio_part_4              | vocab_part_1                                      | vocab_part_2                                           | vocab_part_3                                      | vocab_part_4                        |\n",
    "        |----|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------|---------------------------------------------------------------|---------------------------|---------------------------|---------------------------|---------------------------|---------------------------------------------------|----------------------------------------------------------|---------------------------------------------------|-------------------------------------|\n",
    "        | 1  | I wake up at seven am and get ready for work. By half past eight am, I am at my desk. | In the morning, I start by checking emails and answering phone calls. This keeps me busy. | At noon, I take a break to drink coffee and chat with colleagues. It is a nice time. | In the afternoon, I focus on scheduling meetings. Sometimes, I take a walk to relax. | ./out_folder/row_1/1.mp3 | ./out_folder/row_1/2.mp3 | ./out_folder/row_1/3.mp3 | ./out_folder/row_1/4.mp3 | half past eight am, seven am                      | checking emails, answering phone calls                  | noon, drink coffee, chat with colleagues           | scheduling meetings, take a walk   |\n",
    "        | 2  | I start my work at five pm. I sit at my desk and open my laptop. I have many tasks to do. | At a quarter to six pm, I take a short break. I drink some water and stretch my legs. | When my tasks are completed, I feel happy. I know I have done a good job today. | I feel satisfied and accomplished. It was a productive day at work. | ./out_folder/row_2/1.mp3 | ./out_folder/row_2/2.mp3 | ./out_folder/row_2/3.mp3 | ./out_folder/row_2/4.mp3 | at five pm, desk, laptop                           | at a quarter to six pm, break, water                     | when my tasks are completed, happy, job             | satisfied, accomplished, productive |\n",
    "\n",
    "    - Tham số: \n",
    "        - processing_func là 1 hàm: ... Khi gọi processing_func(paragraph_dict)\n",
    "    - Prompt: \n",
    "        - gen df1\n",
    "            - Từ file_path, tìm đến sheet_name, \n",
    "            - Duyệt qua từng hàng: \n",
    "                - paragraph1 = # get data từ cột content_part_1\n",
    "                - list1 = # get data từ cột vocab_part_1\n",
    "                - Chạy ex1_DIEN_VAO_CHO_TRONG_Dang1Listening(paragraph1, list1)\n",
    "            -   data.append({\n",
    "                \"question\": response_dict[\"question\"],\n",
    "                \"paragraph\": paragraph_text,  # paragraph_dict.get(\"paragraph1, 2, 3, 4\"),     # paragraph1, 2, 3, 4 tương ứng các đoạn luôn\n",
    "                \"answer\": \"\\n\".join([answer.strip() for answer in response_dict.get(\"answers_list\", [])])\n",
    "            - Trả ra được df1\n",
    "\n",
    "        - Tương tự df2, 3, 4    \n",
    "        })\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Process the Excel file to generate content and audio based on the specified processing function.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input Excel file.\n",
    "        sheet_name (str): Name of the sheet to process.\n",
    "        processing_func (callable): Function to process each paragraph.\n",
    "        content_col (str): Name of the column containing content parts.\n",
    "        vocab_col (str): Name of the column containing vocabulary parts.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing processed data.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Initialize list to store data\n",
    "    data = []\n",
    "    \n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        paragraph_text = row[content_col]\n",
    "        vocab_list = row[vocab_col].split(\", \")\n",
    "\n",
    "        try:\n",
    "            # Call the processing function\n",
    "            response_json = processing_func(paragraph_text, vocab_list)\n",
    "            \n",
    "            # Debug: print response_json to check its value\n",
    "            print(f\"Response JSON for row {index}: {response_json}\")\n",
    "            \n",
    "            # Ensure response_json is not empty\n",
    "            if not response_json:\n",
    "                print(f\"Warning: Processing function returned an empty response for row {index}\")\n",
    "                continue\n",
    "            \n",
    "            # Convert JSON string to dictionary\n",
    "            response_dict = json.loads(response_json)\n",
    "            \n",
    "            # Append the result to the data list\n",
    "            data.append({\n",
    "                \"question\": response_dict[\"question\"],\n",
    "                \"paragraph\": paragraph_text,\n",
    "                \"answer\": \"\\n\".join([answer.strip() for answer in response_dict.get(\"answers_list\", [])])\n",
    "            })\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON decode error for row {index}: {e}\")\n",
    "            print(f\"Problematic JSON string: {response_json}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create a DataFrame from the data\n",
    "    output_df = pd.DataFrame(data)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Define the file path and sheet name\n",
    "file_path = r'D:\\OneDrive - Hanoi University of Science and Technology\\ITE10-DS&AI-HUST\\Learn&Task\\PRODUCT_THECOACH\\Task2_ContentGeneration\\ĐÓNG_GÓI_1_FLOW\\output_folder\\output_dang1_LISTENING.xlsx'\n",
    "sheet_name = 'mix_listen_content'\n",
    "\n",
    "\n",
    "\n",
    "# Define the processing functions (assuming these are defined elsewhere in your code)\n",
    "def process_paragraph1(paragraph_text, vocab_list):\n",
    "    return ex1_DIEN_VAO_CHO_TRONG_Dang1Listening(paragraph_text, vocab_list)\n",
    "\n",
    "def process_paragraph2(paragraph_text, vocab_list):\n",
    "    return ex2_CHON_DAP_AN_PHU_HOP_Dang1Listening(paragraph_text, vocab_list)\n",
    "\n",
    "def process_paragraph3(paragraph_text, vocab_list):\n",
    "    return ex3_NOI_DE_TRA_LOI_Dang1Listening(paragraph_text, vocab_list)\n",
    "\n",
    "def process_paragraph4(paragraph_text, vocab_list):\n",
    "    return ex4_DIEN_PHAN_CON_THIEU_Dang1Listening(paragraph_text, vocab_list)\n",
    "\n",
    "# result_df, output_file_path = input_2_gen_content_AND_audio_2_excel(input_file_path, output_folder)\n",
    "\n",
    "\n",
    "# Process each type of paragraph and store in DataFrames\n",
    "df1 = process_excel(file_path, sheet_name, process_paragraph1, 'content_part_1', 'vocab_part_1')\n",
    "df2 = process_excel(file_path, sheet_name, process_paragraph2, 'content_part_2', 'vocab_part_2')\n",
    "df3 = process_excel(file_path, sheet_name, process_paragraph3, 'content_part_3', 'vocab_part_3')\n",
    "df4 = process_excel(file_path, sheet_name, process_paragraph4, 'content_part_4', 'vocab_part_4')\n",
    "\n",
    "# Write all DataFrames to a single Excel file with different sheets\n",
    "output_file_path = 'combined_Dang1Listening_output.xlsx'\n",
    "with pd.ExcelWriter(output_file_path, engine='xlsxwriter') as writer:\n",
    "    result_df.to_excel(writer, sheet_name='mix_listent_content', index=False)\n",
    "    print(f\"Sheet 'Ex1_listen_fill_choose' has been successfully written.\")\n",
    "\n",
    "    df1.to_excel(writer, sheet_name='Ex1_listen_fill_choose', index=False)\n",
    "    print(f\"Sheet 'Ex1_listen_fill_choose' has been successfully written.\")\n",
    "\n",
    "    df2.to_excel(writer, sheet_name='Ex2_listen_choice', index=False)\n",
    "    print(f\"Sheet 'Ex2_listen_choice' has been successfully written.\")\n",
    "    \n",
    "    df3.to_excel(writer, sheet_name='Ex3_listen_speak', index=False)\n",
    "    print(f\"Sheet 'Ex3_listen_speak' has been successfully written.\")\n",
    "\n",
    "    df4.to_excel(writer, sheet_name='Ex4_listen_fill_type', index=False)\n",
    "    print(f\"Sheet 'Ex4_listen_fill_type' has been successfully written.\")\n",
    "\n",
    "print(f\"Data has been successfully written to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
